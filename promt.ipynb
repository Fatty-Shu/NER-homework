{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dc6548",
   "metadata": {},
   "source": [
    "## 背景信息\n",
    "1. 操作步骤1数据预处理已经完成\n",
    "2. 已经生成processed_inputs.npy、processed_outputs.npy、word2idx.pkl、label2idx.pkl、idx2label.pkl\n",
    "3. 训练好的词表示文件是sgns.renmin.bigram-char；该文件首先为词数量和向量维度，使用空格分隔；后续行为中文和向量，中文和向量及向量的具体值都是使用空格隔开的。\n",
    "4. 不需要对预测的训练数据留出测试数据，有专门的测试数据\"./chinese/test_data\"，数据内容同“train_data”，所以不需要单独给测试数据添加加载方法，使用步骤一生成的load_and_preprocess_data方法加载测试数据即可\n",
    "\n",
    "## 任务\n",
    "1. 根据操作步骤1数据预处理结果，完成后续步骤代码生成\n",
    "\n",
    "## 操作步骤\n",
    "1. 数据预处理\n",
    "    （1）在chinese文件夹中找到train_data文件，读取文件的全部内容，第1列为模型的输入数据，第3列对应的标签为模型的最终输出数据。\n",
    "\n",
    "每个句子以空格为分割符，通过判断空格将所有句子读入到input集合中和output集合中。input集合和output集合中的数据是对应关系，例如：input[0]是一个句子，output[0]就是该句子对应的标签。\n",
    "（2）由于句子长短不一，因此要对句子进行处理，将所有句子长度变成相同。句子长度一般可以设置为20、30、40、50个字符等。假设取句子长度为30，那么超过30的进行截断，不足30的填充0。于是，句子就变成了长度为30的序列。\n",
    "（3）这里的标签有7个，分别是： “B-PER （人名的开始部分）、I-PER（人名的中间部分）、B-ORG （组织机构的开始部分）、I-ORG （组织机构的中间部分）、B-LOC （位置的开始部分）、I- LOC（位置的中间部分）、O （非实体信息）”。因此，可以对标签进行编号：1-7。于是，标签就变成了长度为7的序列。\n",
    "2. 构建BILSTM+CRF模型\n",
    "      BILSTM+CRF模型的搭建比较简单，直接调用现成的接口即可。\n",
    "（1）模型的输入\n",
    "     从“https://github.com/Embedding/Chinese-Word-Vectors”下载已经训练好的词表示。经过数据预处理后，训练集的数据都变成了固定长度30个字符。读取第一个句子，并替换成词向量。假设每个单词的词向量长度为300，则第一个句子就变成了30*300的矩阵。\n",
    "（2）模型的输出\n",
    "将第一个句子对应的标签替换成1-7的序号。则第一个句子对应的模型输出为30*7的矩阵。\n",
    "（3）模型的设置\n",
    "因为一次读入一个句子训练有点慢，所以每次我们会读入一批句子，批次大小可以设置为64、128等。这样输入的数据大小为：30*300*128，输出的数据大小为：30*7*128。假设每次取128个句子，但训练集不可能正好是128的倍数，剩余不足128个的句子全部丢弃。\n",
    "设置学习率、LSTM隐藏大小等。\n",
    "3. 训练模型\n",
    "   训练模型，并在测试集上进行测试，测试集的数据处理方式和训练集一致。\n",
    "4. 输出\n",
    "   （1）计算评价指标：P, R, F1。 F1值应该可以达到90%。\n",
    "   （2）生成一个DEMO，随机输入一个句子，输出该句子的标签。\n",
    "\n",
    "\n",
    "标签 B-PER: 13983 次 (0.92%)\n",
    "标签 I-PER: 26122 次 (1.72%)\n",
    "标签 B-ORG: 16199 次 (1.07%)\n",
    "标签 I-ORG: 62941 次 (4.14%)\n",
    "标签 B-LOC: 26163 次 (1.72%)\n",
    "标签 I-LOC: 35011 次 (2.30%)\n",
    "\n",
    "\n",
    "conda activate python1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7cf426",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
